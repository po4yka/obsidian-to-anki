# Multi-Agent AI System Integration Plan

## Overview

This document outlines the plan to integrate the multi-agent AI system (Pre-Validator, Generator, Post-Validator) into the existing obsidian-to-anki codebase.

## Integration Strategy

### 1. Design Principles

- **Backward Compatibility**: Keep existing OpenRouter LLM workflow functional
- **Optional Feature**: Agent system is opt-in via configuration flag
- **Minimal Disruption**: Reuse existing models and utilities where possible
- **Type Safety**: Maintain 100% type hints and mypy compliance
- **Test Coverage**: Maintain 95%+ test coverage

### 2. Architecture Overview

```
Current Flow:
ObsidianParser → APFGenerator (OpenRouter) → AnkiSync

New Agent Flow:
ObsidianParser → AgentOrchestrator → [Pre-Validator → Generator → Post-Validator] → AnkiSync
```

### 3. Component Mapping

| Documentation Component | Implementation Location | Status |
|------------------------|------------------------|---------|
| Pre-Validator Agent | `src/obsidian_anki_sync/agents/pre_validator.py` | To Create |
| Generator Agent | `src/obsidian_anki_sync/agents/generator.py` | To Create |
| Post-Validator Agent | `src/obsidian_anki_sync/agents/post_validator.py` | To Create |
| Agent Orchestrator | `src/obsidian_anki_sync/agents/orchestrator.py` | To Create |
| Ollama Client | `src/obsidian_anki_sync/agents/ollama_client.py` | To Create |
| Validation Models | `src/obsidian_anki_sync/agents/models.py` | To Create |

## Implementation Tasks

### Phase 1: Dependencies & Configuration

#### Task 1.1: Add Dependencies
- Add to `pyproject.toml`:
  - `autogen-ext[ollama]>=0.4.8`
  - `autogen-agentchat>=0.4.0`
  - `pydantic>=2.0.0` (for validation models)

#### Task 1.2: Extend Configuration
- Add to `Config` dataclass in `src/obsidian_anki_sync/config.py`:
  ```python
  # Agent system settings
  use_agent_system: bool = False  # Feature flag
  agent_execution_mode: str = "parallel"  # or "sequential"

  # Ollama settings
  ollama_base_url: str = "http://localhost:11434"

  # Model configurations
  pre_validator_model: str = "qwen3:8b"
  pre_validator_temperature: float = 0.0

  generator_model: str = "qwen3:32b"
  generator_temperature: float = 0.3

  post_validator_model: str = "qwen3:14b"
  post_validator_temperature: float = 0.0

  # Validation settings
  pre_validation_enabled: bool = True
  post_validation_max_retries: int = 3
  post_validation_auto_fix: bool = True
  ```

### Phase 2: Agent Models

#### Task 2.1: Create Pydantic Models
Create `src/obsidian_anki_sync/agents/models.py`:

```python
from pydantic import BaseModel, Field
from typing import Literal, Optional
from datetime import datetime

class PreValidationResult(BaseModel):
    """Result from pre-validator agent."""
    is_valid: bool
    error_type: Literal["format", "structure", "frontmatter", "content", "none"]
    error_details: str = ""
    auto_fix_applied: bool = False
    fixed_content: Optional[str] = None
    validation_time: float = 0.0

class GeneratedCard(BaseModel):
    """Single card generated by generator agent."""
    card_index: int
    slug: str
    lang: str
    apf_html: str
    confidence: float = Field(ge=0.0, le=1.0)

class GenerationResult(BaseModel):
    """Result from generator agent."""
    cards: list[GeneratedCard]
    total_cards: int
    generation_time: float
    model_used: str

class PostValidationResult(BaseModel):
    """Result from post-validator agent."""
    is_valid: bool
    error_type: Literal["syntax", "factual", "semantic", "template", "none"]
    error_details: str = ""
    corrected_cards: Optional[list[GeneratedCard]] = None
    validation_time: float = 0.0

class AgentPipelineResult(BaseModel):
    """Complete result from agent pipeline."""
    success: bool
    pre_validation: PreValidationResult
    generation: Optional[GenerationResult] = None
    post_validation: Optional[PostValidationResult] = None
    total_time: float
    retry_count: int = 0
```

### Phase 3: Ollama Client

#### Task 3.1: Create Ollama Client Wrapper
Create `src/obsidian_anki_sync/agents/ollama_client.py`:

```python
"""Ollama client wrapper for local LLM inference."""
from typing import Any
import httpx
from ..utils.logging import get_logger
from ..utils.retry import retry

logger = get_logger(__name__)

class OllamaClient:
    """Client for Ollama API with retry logic."""

    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.client = httpx.Client(timeout=120.0)

    @retry(max_attempts=3, delay=2.0, backoff=2.0)
    async def generate(
        self,
        model: str,
        prompt: str,
        system: str = "",
        temperature: float = 0.7,
        format: str = "json"
    ) -> dict[str, Any]:
        """Generate completion from Ollama."""
        # Implementation
        pass
```

### Phase 4: Agent Implementations

#### Task 4.1: Pre-Validator Agent
Create `src/obsidian_anki_sync/agents/pre_validator.py`:

- Check note structure (frontmatter, headers, content length)
- Validate markdown syntax
- Return `PreValidationResult` with auto-fix if possible
- Use lightweight model (qwen3:8b)

#### Task 4.2: Generator Agent
Create `src/obsidian_anki_sync/agents/generator.py`:

- Reuse existing APF generation logic from `apf/generator.py`
- Adapt to use Ollama instead of OpenRouter
- Return `GenerationResult` with all generated cards
- Use powerful model (qwen3:32b)

#### Task 4.3: Post-Validator Agent
Create `src/obsidian_anki_sync/agents/post_validator.py`:

- Validate APF HTML syntax using existing `apf/html_validator.py`
- Check semantic coherence
- Attempt auto-fix if validation fails
- Return `PostValidationResult`
- Use medium model (qwen3:14b)

### Phase 5: Agent Orchestrator

#### Task 5.1: Create Orchestrator
Create `src/obsidian_anki_sync/agents/orchestrator.py`:

```python
"""Agent orchestrator for multi-agent pipeline."""
from .pre_validator import PreValidatorAgent
from .generator import GeneratorAgent
from .post_validator import PostValidatorAgent
from .models import AgentPipelineResult
from ..models import NoteMetadata, QAPair

class AgentOrchestrator:
    """Coordinates the three-agent pipeline."""

    def __init__(self, config):
        self.config = config
        self.pre_validator = PreValidatorAgent(config)
        self.generator = GeneratorAgent(config)
        self.post_validator = PostValidatorAgent(config)

    async def process_note(
        self,
        note_content: str,
        metadata: NoteMetadata,
        qa_pairs: list[QAPair]
    ) -> AgentPipelineResult:
        """Run the complete agent pipeline."""

        # Stage 1: Pre-validation
        pre_result = await self.pre_validator.validate(note_content, metadata)
        if not pre_result.is_valid and not pre_result.auto_fix_applied:
            return AgentPipelineResult(
                success=False,
                pre_validation=pre_result,
                total_time=pre_result.validation_time
            )

        # Use fixed content if auto-fix was applied
        content = pre_result.fixed_content or note_content

        # Stage 2: Generation
        gen_result = await self.generator.generate_cards(
            content, metadata, qa_pairs
        )

        # Stage 3: Post-validation with retry
        for attempt in range(self.config.post_validation_max_retries):
            post_result = await self.post_validator.validate(
                gen_result.cards, metadata
            )

            if post_result.is_valid:
                return AgentPipelineResult(
                    success=True,
                    pre_validation=pre_result,
                    generation=gen_result,
                    post_validation=post_result,
                    total_time=sum([...]),
                    retry_count=attempt
                )

            # Auto-fix if enabled
            if self.config.post_validation_auto_fix and post_result.corrected_cards:
                gen_result.cards = post_result.corrected_cards
            else:
                break

        # Failed after retries
        return AgentPipelineResult(
            success=False,
            pre_validation=pre_result,
            generation=gen_result,
            post_validation=post_result,
            total_time=sum([...]),
            retry_count=self.config.post_validation_max_retries
        )
```

### Phase 6: Integration into Existing Workflow

#### Task 6.1: Modify APF Generator
Update `src/obsidian_anki_sync/apf/generator.py`:

```python
class APFGenerator:
    """Generate APF cards from Q&A pairs (with optional agent system)."""

    def __init__(self, config: Config):
        self.config = config

        if config.use_agent_system:
            from ..agents.orchestrator import AgentOrchestrator
            self.orchestrator = AgentOrchestrator(config)
        else:
            # Existing OpenRouter client
            self.client = OpenAI(...)

    async def generate_cards(
        self,
        note_content: str,
        metadata: NoteMetadata,
        qa_pairs: list[QAPair]
    ) -> list[Card]:
        """Generate APF cards (using agent system if enabled)."""

        if self.config.use_agent_system:
            result = await self.orchestrator.process_note(
                note_content, metadata, qa_pairs
            )

            if not result.success:
                logger.error(f"Agent pipeline failed: {result}")
                raise ValueError("Agent pipeline validation failed")

            # Convert GeneratedCard to Card
            return self._convert_agent_cards(result.generation.cards, metadata)
        else:
            # Existing OpenRouter logic
            return await self._generate_via_openrouter(metadata, qa_pairs)
```

#### Task 6.2: Update CLI
Add new CLI options in `src/obsidian_anki_sync/cli.py`:

```python
@app.command()
def sync(
    # ... existing options ...
    use_agents: bool = typer.Option(
        False,
        "--use-agents",
        help="Use multi-agent system for card generation"
    ),
    agent_mode: str = typer.Option(
        "parallel",
        "--agent-mode",
        help="Agent execution mode: parallel or sequential"
    ),
):
    """Synchronize Obsidian notes to Anki."""
    # Override config if flag is set
    if use_agents:
        config.use_agent_system = True
        config.agent_execution_mode = agent_mode
```

### Phase 7: Testing

#### Task 7.1: Unit Tests
- `tests/agents/test_pre_validator.py` - Test pre-validation logic
- `tests/agents/test_generator.py` - Test card generation
- `tests/agents/test_post_validator.py` - Test post-validation
- `tests/agents/test_orchestrator.py` - Test pipeline orchestration

#### Task 7.2: Integration Tests
- `tests/integration/test_agent_pipeline.py` - End-to-end agent flow
- Mock Ollama API responses
- Test error recovery and retry logic

### Phase 8: Documentation

#### Task 8.1: Update README
- Add section on agent system
- Installation instructions for Ollama
- Model download instructions
- Configuration examples

#### Task 8.2: Create Agent Documentation
- `.docs/AGENT_SYSTEM.md` - Detailed agent system documentation
- Prompts for each agent
- Configuration reference
- Troubleshooting guide

## Configuration Examples

### config.yaml (Agent System Enabled)

```yaml
# Feature flags
use_agent_system: true
agent_execution_mode: parallel

# Ollama settings
ollama_base_url: "http://localhost:11434"

# Pre-Validator Agent
pre_validator_model: "qwen3:8b"
pre_validator_temperature: 0.0
pre_validation_enabled: true

# Generator Agent
generator_model: "qwen3:32b"
generator_temperature: 0.3

# Post-Validator Agent
post_validator_model: "qwen3:14b"
post_validator_temperature: 0.0
post_validation_max_retries: 3
post_validation_auto_fix: true

# Keep existing OpenRouter settings for fallback
openrouter_model: "openai/gpt-4"
llm_temperature: 0.2
```

## Backward Compatibility

1. **Default Behavior**: Agent system is OFF by default (`use_agent_system: false`)
2. **Existing Tests**: All 81 existing tests should pass without modification
3. **Graceful Fallback**: If Ollama is unavailable, fall back to OpenRouter
4. **CLI Compatibility**: All existing CLI commands work unchanged

## Performance Considerations

1. **Memory**: Agent system requires ~30-34GB RAM (per documentation)
2. **Speed**: Pre-validator saves 15-20% time by early rejection
3. **Parallel Execution**: All three agents can run simultaneously on M4 Max
4. **Sequential Mode**: For lower-spec machines, run agents sequentially

## Risk Mitigation

| Risk | Mitigation |
|------|------------|
| Ollama not installed | Detect at startup, show helpful error message |
| Models not downloaded | Check availability, provide download instructions |
| Insufficient memory | Offer sequential mode, smaller models |
| Agent validation too strict | Make strictness configurable |
| Regression in existing features | Comprehensive testing, feature flag |

## Success Criteria

- [ ] Agent system functional with all three agents
- [ ] All 81 existing tests pass
- [ ] New agent tests achieve 95%+ coverage
- [ ] Agent system is opt-in via configuration
- [ ] Documentation complete and clear
- [ ] Performance benchmarks documented
- [ ] Graceful error handling for missing dependencies

## Timeline Estimate

| Phase | Tasks | Est. Time |
|-------|-------|-----------|
| 1. Dependencies & Config | 2 tasks | 30 min |
| 2. Agent Models | 1 task | 45 min |
| 3. Ollama Client | 1 task | 1 hour |
| 4. Agent Implementations | 3 tasks | 3 hours |
| 5. Agent Orchestrator | 1 task | 1.5 hours |
| 6. Integration | 2 tasks | 2 hours |
| 7. Testing | 2 tasks | 2 hours |
| 8. Documentation | 2 tasks | 1 hour |
| **Total** | **14 tasks** | **~12 hours** |

## Next Steps

1. Review and approve this integration plan
2. Begin with Phase 1: Dependencies & Configuration
3. Implement incrementally, testing at each phase
4. Maintain backward compatibility throughout
5. Document as we build
