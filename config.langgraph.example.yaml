# Example configuration for LangGraph + PydanticAI agent system
# This configuration enables the new agentic system with:
# - PydanticAI for structured outputs and type-safe agents
# - LangGraph for workflow orchestration with state management
# - OpenRouter as the LLM provider for access to multiple models
#
# Copy this file to config.yaml and customize for your setup.

# =============================================================================
# Basic Configuration
# =============================================================================

# Obsidian vault path (required)
vault_path: ~/Documents/ObsidianVault

# Source directory within vault containing notes to sync
source_dir: interview_questions/InterviewQuestions

# Anki connection settings
anki_connect_url: http://127.0.0.1:8765
anki_deck_name: Interview Questions
anki_note_type: APF::Simple

# Runtime mode
run_mode: apply # or 'dry-run' for testing
delete_mode: delete # or 'archive' to preserve cards

# Database and logging
db_path: .sync_state.db
log_level: INFO # DEBUG, INFO, WARNING, ERROR, CRITICAL

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# Provider selection: openrouter, ollama, or lm_studio
llm_provider: openrouter

# OpenRouter settings (required when llm_provider = openrouter)
# Get API key from: https://openrouter.ai/
# Set via environment variable: OPENROUTER_API_KEY=your_key_here
openrouter_base_url: https://openrouter.ai/api/v1
openrouter_site_url: https://yoursite.com # Optional, for rankings
openrouter_site_name: Your App Name # Optional, for rankings

# Common LLM settings
llm_temperature: 0.2
llm_top_p: 0.3
llm_timeout: 900.0 # 15 minutes
llm_max_tokens: 2048

# =============================================================================
# LangGraph + PydanticAI Agent System (NEW!)
# =============================================================================

# Enable the new LangGraph-based workflow orchestration
use_langgraph: true

# Enable PydanticAI for type-safe structured outputs
use_pydantic_ai: true

# Per-agent model overrides (OpenRouter model identifiers)
# Optimized 2025 models: MiniMax M2, Kimi K2, DeepSeek V3, Qwen 2.5

# Pre-validator: Fast, efficient validation
pre_validator_model: qwen/qwen-2.5-32b-instruct

# Generator: Powerful content creation
generator_model: qwen/qwen-2.5-72b-instruct

# Post-validator: Strong reasoning and quality checks
post_validator_model: deepseek/deepseek-chat

# Card Splitting: Advanced reasoning for decision making
card_splitting_model: moonshotai/kimi-k2-thinking

# Context Enrichment: Excellent for code generation and creative examples
context_enrichment_model: minimax/minimax-m2

# Memorization Quality: Strong analytical capabilities
memorization_quality_model: moonshotai/kimi-k2

# Duplicate Detection: Efficient comparison
duplicate_detection_model: qwen/qwen-2.5-32b-instruct

# LangGraph workflow settings
langgraph_max_retries: 3 # Maximum post-validation retry attempts
langgraph_auto_fix: true # Enable automatic error fixing
langgraph_strict_mode: true # Use strict validation rules
langgraph_checkpoint_enabled: true # Enable state persistence

# =============================================================================
# Legacy Agent System
# =============================================================================

# Set to false when using LangGraph system
use_agent_system: false

# Agent settings (shared between legacy and LangGraph systems)
pre_validation_enabled: true
post_validation_max_retries: 3
post_validation_auto_fix: true
post_validation_strict_mode: true

# =============================================================================
# Deck Export Settings (Optional)
# =============================================================================

export_deck_name: Interview Questions Export
export_deck_description: Generated flashcards for interview preparation
export_output_path: ./exports/interview_questions.apkg
# =============================================================================
# Usage Notes
# =============================================================================
# 1. Set OPENROUTER_API_KEY environment variable or create .env file:
#    echo "OPENROUTER_API_KEY=your_key_here" > .env
#
# 2. The LangGraph system provides:
#    - Automatic retry logic with state persistence
#    - Conditional routing based on validation results
#    - Type-safe structured outputs via PydanticAI
#    - Better error handling and debugging
#
# 3. Recommended model combinations (2025 optimized):
#    - Cost-Optimized: qwen-2.5-32b for all agents
#    - Balanced (default): Qwen 2.5 for core tasks, specialized models for enhancements
#    - High-Quality: qwen-2.5-72b for all agents + DeepSeek V3 for validation
#
# 4. Latest OpenRouter models (2025):
#    - MiniMax M2: Excellent for coding and agentic workflows (minimax/minimax-m2)
#    - Kimi K2: Strong reasoning and tool use (moonshotai/kimi-k2)
#    - Kimi K2 Thinking: Advanced reasoning (moonshotai/kimi-k2-thinking)
#    - DeepSeek V3: Latest stable version (deepseek/deepseek-chat)
#    - DeepSeek V3.2-Exp: Experimental long-context (deepseek/deepseek-v3.2-exp)
#    - Qwen 2.5 72B: Large general model (qwen/qwen-2.5-72b-instruct)
#    - Qwen 2.5 32B: Medium general model (qwen/qwen-2.5-32b-instruct)
#
# 5. Cost optimization tips:
#    - Use qwen-2.5-32b for validators (fast and cost-effective)
#    - Reserve qwen-2.5-72b for generation only
#    - Set langgraph_max_retries=1 to reduce API calls
#    - Use strict_mode=false for more lenient validation
#    - Enable OpenRouter's :floor suffix for lowest-price routing
#
# 5. For local models (Ollama/LM Studio):
#    - Set llm_provider: ollama or lm_studio
#    - Local models work but PydanticAI features may be limited
#    - Structured outputs require compatible models
#
# =============================================================================
