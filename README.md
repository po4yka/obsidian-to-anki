# Obsidian to Anki APF Sync Service

Synchronize Obsidian Q&A notes to Anki APF cards using LLM-powered generation with optional local multi-agent AI system.

[![Tests](https://img.shields.io/badge/tests-81%20passed-brightgreen)]()
[![Python](https://img.shields.io/badge/python-3.11%2B-blue)]()
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## Features

- Parse Obsidian markdown notes with Q&A pairs
- **Multi-Provider LLM Support**: Choose from **Ollama**, **LM Studio**, **OpenAI**, **Anthropic**, or **OpenRouter**
- **100% Privacy**: Optional fully local processing with no cloud APIs
- Bidirectional synchronization (create/update/delete/restore)
- Bilingual card support (EN/RU)
- Stable slug-based tracking with collision resolution
- SQLite state management with proper connection handling
- Dry-run mode for previewing changes
- Three-stage validation pipeline with auto-fix
- Unified provider configuration with single point of model specification
- **Security**: Path traversal protection, symlink attack prevention, input validation

## Multi-Agent AI System

This project now supports a sophisticated **multi-agent AI system** for generating Anki flashcards using local LLMs running on Apple Silicon via Ollama.

### Architecture

```
┌─────────────────┐
│ Obsidian Note   │
└────────┬────────┘
         │
         ▼
┌─────────────────────────┐
│  Pre-Validator Agent    │  Fast structural validation
│  (Qwen3-8B)             │  • Check formatting
│                         │  • Verify structure
└────────┬────────────────┘  • Validate syntax
         │
         ▼ (if valid)
┌─────────────────────────┐
│  Generator Agent        │  High-quality generation
│  (Qwen3-32B)            │  • Parse markdown
│                         │  • Extract concepts
└────────┬────────────────┘  • Create card pairs
         │
         ▼
┌─────────────────────────┐
│  Validator Agent        │  Quality assurance
│  (Qwen3-14B)            │  • Check syntax
│                         │  • Verify facts
└────────┬────────────────┘  • Ensure coherence
         │
         ▼ (if valid)
┌─────────────────┐
│  Anki Card      │
└─────────────────┘
```

### Benefits

| Benefit | Description |
|---------|-------------|
| **15-20% faster** | Pre-validator rejects malformed notes early |
| **Higher quality** | Independent validation catches errors before sync |
| **Auto-fix** | Automatic retry with corrections |
| **Privacy-first** | 100% local processing, no cloud APIs |
| **Cost-effective** | No API costs after initial model download |
| **Better accuracy** | Three-stage validation ensures quality |

### System Requirements

#### Minimum (Basic Operation)
- **Mac**: M3 or M4 series (any variant)
- **RAM**: 32GB unified memory
- **Storage**: 25GB for models
- **Performance**: ~600 cards/hour (sequential mode)

#### Recommended (Optimal Performance)
- **Mac**: M4 Max or M4 Ultra
- **RAM**: 48GB+ unified memory
- **Storage**: 50GB for models and cache
- **Performance**: ~1200 cards/hour (parallel mode)

### Quick Start with Agents

#### 1. Install Ollama

```bash
# Install via Homebrew
brew install ollama

# Start Ollama service (keep this running)
ollama serve
```

#### 2. Download Models

```bash
# Download all three models
ollama pull qwen3:8b   # Pre-validator (~5GB)
ollama pull qwen3:32b  # Generator (~20GB)
ollama pull qwen3:14b  # Post-validator (~8GB)

# Verify installation
ollama list
```

#### 3. Configure Agent System

**Option A: Use example config**
```bash
cp config.agents.example.yaml config.yaml
# Edit config.yaml with your vault path
```

**Option B: Minimal config.yaml**
```yaml
# Basic settings
vault_path: "~/Documents/ObsidianVault"
source_dir: "Notes"

# Anki settings
anki_connect_url: "http://127.0.0.1:8765"
anki_deck_name: "My Deck"

# Enable agent system
use_agent_system: true
ollama_base_url: "http://localhost:11434"

# Agent models (defaults shown)
pre_validator_model: "qwen3:8b"
generator_model: "qwen3:32b"
post_validator_model: "qwen3:14b"
```

#### 4. Run with Agents

```bash
# Sync with agent system
obsidian-anki-sync sync --use-agents

# Test run (process 5 random notes)
obsidian-anki-sync test-run --count 5 --use-agents

# Dry run (preview without applying)
obsidian-anki-sync sync --use-agents --dry-run
```

### Agent vs OpenRouter Comparison

| Feature | Agent System | OpenRouter |
|---------|-------------|------------|
| **Privacy** | 100% Local | Cloud API |
| **Cost** | Free after download | Per-token pricing |
| **Quality** | Three-stage validation | Single-pass |
| **Speed** | First run slower | Fast API calls |
| **Requirements** | 32GB+ RAM, M3+ Mac | Any system |
| **Setup** | Install Ollama + models | API key only |
| **Offline** | Works offline | Requires internet |
| **Validation** | Pre + Post validation | None |
| **Auto-fix** | Automatic corrections | Manual fixes |

**When to use which:**
- **Use Agent System** if you:
  - Have a compatible Mac (M3/M4)
  - Value privacy and data control
  - Process notes frequently (100+ notes)
  - Want higher quality with validation
  - Work offline or with sensitive data

- **Use OpenRouter** if you:
  - Need quick setup (5 minutes)
  - Have limited hardware (< 32GB RAM)
  - Process notes infrequently (< 50 notes)
  - Prefer cloud-based solutions
  - Don't have Apple Silicon

## Multiple LLM Provider Support

The service now supports **five LLM providers** with a unified configuration system:

### Supported Providers

| Provider | Type | Best For | Setup Difficulty |
|----------|------|----------|------------------|
| **Ollama** | Local/Cloud | Privacy, offline usage | Easy (CLI) |
| **LM Studio** | Local | GUI preference, model testing | Easy (GUI) |
| **OpenAI** | Cloud | GPT-4, GPT-4 Turbo models | Easy (API key) |
| **Anthropic** | Cloud | Claude 3 models (Opus, Sonnet, Haiku) | Easy (API key) |
| **OpenRouter** | Cloud | Multi-model gateway, SOTA access | Easy (API key) |

### Configuration

Choose your provider in `config.yaml`:

```yaml
# Provider selection
llm_provider: "ollama"  # Options: "ollama", "lm_studio", "openai", "anthropic", "openrouter"

# Provider-specific settings (only configure what you use)

# Ollama (local/cloud LLMs)
ollama_base_url: "http://localhost:11434"
# ollama_api_key: "sk-..."  # Only for Ollama Cloud

# LM Studio (local GUI)
lm_studio_base_url: "http://localhost:1234/v1"

# OpenAI (GPT models)
# openai_api_key: "sk-..."  # Or set OPENAI_API_KEY env var
# openai_base_url: "https://api.openai.com/v1"  # Optional custom endpoint

# Anthropic (Claude models)
# anthropic_api_key: "sk-ant-..."  # Or set ANTHROPIC_API_KEY env var
# anthropic_base_url: "https://api.anthropic.com"

# OpenRouter (multi-model gateway)
# openrouter_api_key: "sk-or-..."  # Or set OPENROUTER_API_KEY env var

# Model specifications (adjust for your provider)
pre_validator_model: "qwen3:8b"           # For Ollama
generator_model: "qwen3:32b"              # For Ollama
post_validator_model: "qwen3:14b"         # For Ollama

# For OpenAI:
# generator_model: "gpt-4-turbo-preview"
# post_validator_model: "gpt-4"
# pre_validator_model: "gpt-3.5-turbo"

# For Anthropic:
# generator_model: "claude-3-opus-20240229"
# post_validator_model: "claude-3-sonnet-20240229"
# pre_validator_model: "claude-3-haiku-20240307"
```

### Quick Setup Examples

**Ollama (Local):**
```bash
brew install ollama
ollama serve
ollama pull qwen3:8b qwen3:14b qwen3:32b
```

**LM Studio:**
1. Download from https://lmstudio.ai
2. Load models through GUI
3. Start local server
4. Set `llm_provider: "lm_studio"`

**OpenAI:**
```bash
# Get API key from https://platform.openai.com/api-keys
export OPENAI_API_KEY="sk-..."

# Or in config.yaml
echo "openai_api_key: sk-..." >> config.yaml
```

**Anthropic (Claude):**
```bash
# Get API key from https://console.anthropic.com/
export ANTHROPIC_API_KEY="sk-ant-..."

# Or in config.yaml
echo "anthropic_api_key: sk-ant-..." >> config.yaml
```

**OpenRouter:**
```bash
# Get API key from https://openrouter.ai/keys
export OPENROUTER_API_KEY="sk-or-..."

# Or in config.yaml
echo "openrouter_api_key: sk-or-..." >> config.yaml
```

### Documentation

- **Full Provider Guide:** [docs/LLM_PROVIDERS.md](docs/LLM_PROVIDERS.md)
- **Example Config:** [config.providers.example.yaml](config.providers.example.yaml)
- **API Reference:** [src/obsidian_anki_sync/providers/README.md](src/obsidian_anki_sync/providers/README.md)

## Installation

This project uses [uv](https://docs.astral.sh/uv/) for fast, reliable dependency management.

### Prerequisites

**Required:**
- Python 3.11 or higher
- [uv](https://docs.astral.sh/uv/) package manager
- Anki with [AnkiConnect](https://ankiweb.net/shared/info/2055492159) addon

**Optional (for agent system):**
- macOS with Apple Silicon (M3/M4)
- 32GB+ RAM
- [Ollama](https://ollama.ai/)

### Setup Steps

#### 1. Install uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

#### 2. Clone Repository

```bash
git clone https://github.com/po4yka/obsidian-to-anki.git
cd obsidian-to-anki
```

#### 3. Install Dependencies

```bash
# Install all dependencies (including dev tools)
uv sync --all-extras

# This will:
# - Create .venv with Python 3.11+
# - Install all dependencies from uv.lock
# - Install project in editable mode
```

#### 4. Activate Virtual Environment

```bash
source .venv/bin/activate  # Unix/macOS
# or
.venv\Scripts\activate     # Windows
```

#### 5. Install Anki Integration

1. Download [Anki](https://apps.ankiweb.net/)
2. Install AnkiConnect addon:
   - In Anki: Tools → Add-ons → Get Add-ons
   - Code: `2055492159`
   - Restart Anki

#### 6. (Optional) Install Ollama for Agent System

```bash
# macOS only
brew install ollama

# Start Ollama service
ollama serve

# Download models (run in another terminal)
ollama pull qwen3:8b
ollama pull qwen3:32b
ollama pull qwen3:14b
```

## Usage

### Basic Usage (OpenRouter)

#### 1. Configure

Create a `.env` file or `config.yaml`:

```bash
# .env
VAULT_PATH=/path/to/obsidian/vault
SOURCE_DIR=Notes
OPENROUTER_API_KEY=your_api_key_here
ANKI_DECK_NAME=My Deck
```

Or use `config.yaml`:

```yaml
vault_path: "/path/to/obsidian/vault"
source_dir: "Notes"
anki_deck_name: "My Deck"
openrouter_model: "openai/gpt-4"
```

#### 2. Run Sync

```bash
# Full sync
obsidian-anki-sync sync

# Dry run (preview changes)
obsidian-anki-sync sync --dry-run

# Test with sample
obsidian-anki-sync test-run --count 10
```

### Advanced Usage (Agent System)

#### CLI Options

```bash
# Enable agents via CLI flag
obsidian-anki-sync sync --use-agents

# Disable agents (use OpenRouter)
obsidian-anki-sync sync --no-agents

# Test run with agents
obsidian-anki-sync test-run --count 5 --use-agents

# Dry run with agents
obsidian-anki-sync sync --use-agents --dry-run
```

#### Configuration

```yaml
# config.yaml (full agent configuration)

# Feature flags
use_agent_system: true
agent_execution_mode: "parallel"  # or "sequential"

# Ollama connection
ollama_base_url: "http://localhost:11434"

# Pre-Validator (structure checks)
pre_validator_model: "qwen3:8b"
pre_validator_temperature: 0.0
pre_validation_enabled: true

# Generator (card creation)
generator_model: "qwen3:32b"
generator_temperature: 0.3

# Post-Validator (quality checks)
post_validator_model: "qwen3:14b"
post_validator_temperature: 0.0
post_validation_max_retries: 3
post_validation_auto_fix: true
post_validation_strict_mode: true
```

### Diagnostic Commands

```bash
# List available Anki decks
obsidian-anki-sync decks

# List available note types
obsidian-anki-sync models

# Show fields for a note type
obsidian-anki-sync model-fields --model "APF::Simple"

# Initialize config and database
obsidian-anki-sync init

# Validate note structure
obsidian-anki-sync validate path/to/note.md
```

## Performance

### Agent System Benchmarks

Tested on MacBook M4 Max (48GB RAM):

| Task | Processing Speed | Memory Usage | Pre-Val Rejection |
|------|-----------------|--------------|-------------------|
| Simple notes (5 cards) | 14 cards/min | 30GB | ~10% |
| Medium notes (15 cards) | 10 cards/min | 32GB | ~15% |
| Complex notes (30 cards) | 5 cards/min | 34GB | ~20% |

**Total throughput**: ~1200 cards/hour with tri-agent validation

**Efficiency gain**: Pre-validator saves 2-3 minutes per rejected note

### OpenRouter Performance

| Task | Processing Speed | Cost (approx) |
|------|-----------------|---------------|
| Simple notes (5 cards) | 20 cards/min | $0.05/note |
| Medium notes (15 cards) | 15 cards/min | $0.12/note |
| Complex notes (30 cards) | 8 cards/min | $0.25/note |

## Development

### Code Style

```bash
# Format code
uv run black .

# Sort imports
uv run isort .

# Lint code
uv run ruff check .

# Type check
uv run mypy src/
```

### Testing

```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=src/obsidian_anki_sync

# Run specific test
uv run pytest tests/test_agents.py -v
```

### Pre-commit Hooks

```bash
# Install hooks
pre-commit install

# Run manually
pre-commit run --all-files
```

## Troubleshooting

### Agent System Issues

#### Ollama Connection Failed

```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Start Ollama
ollama serve

# Verify models are installed
ollama list
```

#### Out of Memory

```yaml
# Use sequential mode in config.yaml
agent_execution_mode: "sequential"

# Or use smaller models
generator_model: "qwen3:14b"  # Instead of 32b
```

#### Models Not Loading

```bash
# Re-download corrupted models
ollama rm qwen3:32b
ollama pull qwen3:32b

# Check available space
df -h
```

### OpenRouter Issues

#### API Key Invalid

```bash
# Test API key
curl https://openrouter.ai/api/v1/models \
  -H "Authorization: Bearer YOUR_API_KEY"
```

### Anki Issues

#### AnkiConnect Not Responding

1. Ensure Anki is running
2. Check AnkiConnect is enabled: Tools → Add-ons
3. Verify port: Tools → Add-ons → AnkiConnect → Config
4. Default port should be `8765`

### Common Issues

#### Import Errors

```bash
# Reinstall dependencies
uv sync --all-extras

# Or use pip
pip install -e ".[dev]"
```

#### Permission Errors

```bash
# Fix permissions
chmod -R 755 .venv/
```

## Security Features

This project implements multiple security measures to protect your data:

### Path Security
- **Path Traversal Prevention**: Source directories are validated to prevent `..` escapes
- **Symlink Attack Prevention**: Symlinks are blocked by default (configurable)
- **Vault Boundary Enforcement**: All note paths must be within the vault directory
- **Filename Sanitization**: Automatic removal of dangerous characters from filenames

### API Security
- **API Key Validation**: Provider-specific validation at startup with helpful error messages
- **Environment Variable Support**: Secure key storage via environment variables
- **No Hardcoded Secrets**: All sensitive data loaded from config or environment

### Error Handling
- **Specific Exception Types**: No bare `except:` blocks that could mask errors
- **Detailed Error Logging**: All errors include context and suggestions
- **Resource Cleanup**: Proper context manager usage for database connections

### Configuration Validation
All configuration values are validated at startup:
- Vault path existence and permissions
- Source directory within vault boundaries
- Database path validity
- API keys for selected providers
- Model specifications

## Documentation

- **[Agent Integration Plan](.docs/AGENT_INTEGRATION_PLAN.md)** - Detailed architecture and implementation
- **[Configuration Example](config.agents.example.yaml)** - Fully commented configuration
- **[Requirements](.docs/REQUIREMENTS.md)** - Project specifications
- **[APF Format](.docs/APF_FORMAT.md)** - Card format specification
- **[Cards Prompt](.docs/CARDS_PROMPT.md)** - LLM generation instructions
- **[Security Best Practices](#-security-features)** - See above section

## Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests: `uv run pytest`
5. Format code: `uv run black . && uv run isort .`
6. Submit a pull request

## License

MIT License - see [LICENSE](LICENSE) for details

## Acknowledgments

- Built with [Typer](https://typer.tiangolo.com/) and [Rich](https://rich.readthedocs.io/)
- Multi-agent system powered by [Ollama](https://ollama.ai/) and [Qwen3](https://huggingface.co/Qwen)
- APF format based on SuperMemo principles
- Inspired by the Anki community

---

**Need help?** Open an issue on [GitHub](https://github.com/po4yka/obsidian-to-anki/issues)
